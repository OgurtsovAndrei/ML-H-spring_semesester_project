{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (2.0.6)\r\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from pytorch-lightning) (1.25.2)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from pytorch-lightning) (2.0.1)\r\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from pytorch-lightning) (4.65.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from pytorch-lightning) (6.0.1)\r\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from pytorch-lightning) (2023.6.0)\r\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from pytorch-lightning) (1.0.1)\r\n",
      "Requirement already satisfied: packaging>=17.1 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from pytorch-lightning) (23.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from pytorch-lightning) (4.7.1)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from pytorch-lightning) (0.9.0)\r\n",
      "Requirement already satisfied: requests in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\r\n",
      "Requirement already satisfied: filelock in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\r\n",
      "Requirement already satisfied: sympy in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\r\n",
      "Requirement already satisfied: networkx in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.99)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.99)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.101)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (8.5.0.96)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.10.3.66)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (10.9.0.58)\r\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (10.2.10.91)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.4.0.1)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.4.91)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (2.14.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (11.7.91)\r\n",
      "Requirement already satisfied: triton==2.0.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\r\n",
      "Requirement already satisfied: setuptools in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->pytorch-lightning) (68.0.0)\r\n",
      "Requirement already satisfied: wheel in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->pytorch-lightning) (0.41.0)\r\n",
      "Requirement already satisfied: cmake in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.27.0)\r\n",
      "Requirement already satisfied: lit in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.6)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/andrey/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import multiprocessing\n",
    "from typing import Tuple, Any\n",
    "!pip install pytorch-lightning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:05.390909810Z",
     "start_time": "2023-08-06T17:51:03.226907823Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:09.764767780Z",
     "start_time": "2023-08-06T17:51:05.395420216Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from src.tools import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:09.789725486Z",
     "start_time": "2023-08-06T17:51:09.766585184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=3, edgeitems=20, linewidth=250)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "np.set_printoptions(precision=3, suppress=True, edgeitems=20, linewidth=250)\n",
    "INT_BITS = 32\n",
    "INT_MAX = (1 << (INT_BITS - 1)) - 1\n",
    "INT_MIN = -(1 << (INT_BITS - 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:09.790365720Z",
     "start_time": "2023-08-06T17:51:09.775887177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class AND(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.l1 = nn.Sequential(nn.Linear(2, 1), nn.ReLU())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.l1[0].weight.fill_(1.0)\n",
    "            self.l1[0].bias.fill_(-1.0)\n",
    "        \n",
    "        for layer in self.l1:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight = nn.Parameter(layer.weight.double())\n",
    "                layer.bias = nn.Parameter(layer.bias.double())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x.double())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:09.791128174Z",
     "start_time": "2023-08-06T17:51:09.783078572Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class OR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.l1 = nn.Sequential(nn.Linear(2, 1), nn.Hardtanh(max_val=1.0, min_val=-1.0))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.l1[0].weight.fill_(1.0)\n",
    "            self.l1[0].bias.fill_(0)\n",
    "        \n",
    "        for layer in self.l1:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight = nn.Parameter(layer.weight.double())\n",
    "                layer.bias = nn.Parameter(layer.bias.double())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x.double())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:09.825089652Z",
     "start_time": "2023-08-06T17:51:09.790851255Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "class XOR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vals = [AND(), OR()]\n",
    "        \n",
    "        for layer in self.vals:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight = nn.Parameter(layer.weight.double())\n",
    "                layer.bias = nn.Parameter(layer.bias.double())\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred1 = self.vals[0](x)\n",
    "        pred2 = self.vals[1](x)\n",
    "        # print(torch.concatenate([torch.ones_like(pred1) - pred1, pred2], axis=-1))\n",
    "        reshaped = torch.concatenate([torch.ones_like(pred1) - pred1, pred2], axis=-1)\n",
    "        return self.vals[0](reshaped)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T18:16:39.717651151Z",
     "start_time": "2023-08-06T18:16:39.668031903Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.],\n        [0.],\n        [0.],\n        [1.]], dtype=torch.float64, grad_fn=<ReluBackward0>)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "and1 = AND()\n",
    "and1.forward(torch.tensor([[0, 0], [1, 0], [0, 1], [1, 1]], dtype=torch.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:09.905810077Z",
     "start_time": "2023-08-06T17:51:09.835734340Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.],\n        [1.],\n        [1.],\n        [0.]], dtype=torch.float64, grad_fn=<ReluBackward0>)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor = XOR()\n",
    "list(xor.parameters())\n",
    "xor.forward(torch.tensor([[0, 0], [1, 0], [0, 1], [1, 1]], dtype=torch.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:09.964828785Z",
     "start_time": "2023-08-06T17:51:09.886840893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "class SumBinModule(nn.Module):\n",
    "    def __init__(self, n_bits = 32):\n",
    "        super().__init__()\n",
    "        self.XOR = XOR()\n",
    "        self.AND = AND()\n",
    "        self.OR = OR()\n",
    "        \n",
    "    def forward(self, x:  torch.Tensor):\n",
    "        \n",
    "        reshaped = x.reshape(x.shape[0], 2, x.shape[1] // 2)\n",
    "        transposed = torch.transpose(reshaped, 1, 2)\n",
    "        \n",
    "        # after_and = reshaped.apply(self.AND)\n",
    "        # after_xor = reshaped.apply(self.XOR)\n",
    "        # print(after_and)\n",
    "        # print(after_xor)\n",
    "        after_and = self.AND(transposed)\n",
    "        after_xor = self.XOR(transposed)\n",
    "        print(\"After AND\")\n",
    "        print(after_and)\n",
    "        after_roll = torch.roll(after_and, -1)\n",
    "        print(after_roll)\n",
    "        after_roll[:, -1, 0] = 0.0\n",
    "        \n",
    "        concat = torch.concatenate((after_roll, after_xor), axis=-1)\n",
    "        print(concat)\n",
    "        return torch.flatten(self.XOR(concat), start_dim=1)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T18:24:37.920450613Z",
     "start_time": "2023-08-06T18:24:37.877354905Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After AND\n",
      "tensor([[[0.],\n",
      "         [0.],\n",
      "         [1.]]], dtype=torch.float64, grad_fn=<ReluBackward0>)\n",
      "tensor([[[0.],\n",
      "         [1.],\n",
      "         [0.]]], dtype=torch.float64, grad_fn=<RollBackward0>)\n",
      "tensor([[[0., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.]]], dtype=torch.float64, grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.]], dtype=torch.float64, grad_fn=<ReshapeAliasBackward0>)"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summer = SumBinModule()\n",
    "summer.forward(torch.tensor([[0, 0, 1,\n",
    "                              1, 1, 1],\n",
    "                             # [0, 1, 1, 0, 1, 1]\n",
    "                             ], dtype=torch.float32))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T18:24:38.298160679Z",
     "start_time": "2023-08-06T18:24:38.285886811Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "class SumNaturalBinAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, encoder: SumBinModule, loss_function=F.mse_loss, lr=3 * 1e-3):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.loss_function = loss_function\n",
    "        self.lr = lr\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.encoder(x)\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_accuracy(y_hat, y) -> tuple[float, float]:\n",
    "        eq = (y == torch.round(y_hat))\n",
    "        return eq.all(axis=1).double().mean(), eq.double().mean()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.encoder(x)\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        acc, bin_acc = self._get_accuracy(y_hat, y)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": loss, \"test_bin_acc\": bin_acc}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=2.5 * 1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.encoder(x)\n",
    "        val_loss = self.loss_function(y_hat, y)\n",
    "        acc, bin_acc = self._get_accuracy(y_hat, y)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": val_loss, \"test_bin_acc\": bin_acc}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "        # Return the validation loss and any other metrics you computed\n",
    "        # return {'val_loss': val_loss, 'val_accuracy': accuracy}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:09.967260162Z",
     "start_time": "2023-08-06T17:51:09.933814810Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:10.418648440Z",
     "start_time": "2023-08-06T17:51:09.934400218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "class SimpleRandomNaturalBinSumDataset(Dataset):\n",
    "    def __init__(self, size, transform=None, target_transform=None):\n",
    "        self.size = size\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        ints1 = np.random.randint(INT_MIN, INT_MAX, size=self.size, dtype=np.int32)\n",
    "        ints2 = np.random.randint(INT_MIN, INT_MAX, size=self.size, dtype=np.int32)\n",
    "\n",
    "        array1 = np.array([SimpleRandomNaturalBinSumDataset.decompose_to_bool_array(i) for i in tqdm(ints1)])\n",
    "        array2 = np.array([SimpleRandomNaturalBinSumDataset.decompose_to_bool_array(i) for i in tqdm(ints2)])\n",
    "        self.X = np.concatenate((array1.reshape((self.size, INT_BITS)),\n",
    "                                 array2.reshape((self.size, INT_BITS))), axis=1)\n",
    "\n",
    "        self.labels = np.array([SimpleRandomNaturalBinSumDataset.decompose_to_bool_array(i) for i in\n",
    "                                tqdm((ints1 + ints2) % (1 << INT_BITS) + INT_MIN)])\n",
    "\n",
    "    @staticmethod\n",
    "    def compose_from_bool_array(bool_array):\n",
    "        if not isinstance(bool_array, np.ndarray):\n",
    "            raise ValueError(\"bool_array should be a numpy ndarray.\")\n",
    "\n",
    "        if bool_array.shape != (INT_BITS,):\n",
    "            raise ValueError(\"bool_array should be a 1-dimensional array of size 32.\")\n",
    "\n",
    "        binary_str = \"\".join(str(int(bit)) for bit in bool_array)\n",
    "        first_bit = binary_str[0]\n",
    "        number_str = binary_str[1:]\n",
    "\n",
    "        if first_bit == '0':\n",
    "            return int(number_str, 2)\n",
    "        else:\n",
    "            return int(number_str, 2) + INT_MIN\n",
    "\n",
    "    @staticmethod\n",
    "    def decompose_to_bool_array(number):\n",
    "        if not isinstance(number, np.int32) and not isinstance(number, np.int64) and not isinstance(number, int):\n",
    "            raise ValueError(f\"Number should be an integer. Received {type(number)}\")\n",
    "\n",
    "        if number < 0:\n",
    "            return SimpleRandomNaturalBinSumDataset._decompose_positive_add_first_bit(number - INT_MIN, str(1))\n",
    "        else:\n",
    "            return SimpleRandomNaturalBinSumDataset._decompose_positive_add_first_bit(number, str(0))\n",
    "\n",
    "    @staticmethod\n",
    "    def _decompose_positive_add_first_bit(number, first_bit: str):\n",
    "        binary_str = first_bit + bin(number)[2:].zfill(31)\n",
    "        bool_array = np.array([int(bit) for bit in binary_str], dtype=np.float64)\n",
    "        return bool_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        values, labels = self.X[idx], self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            values = self.transform(values)\n",
    "        if self.target_transform:\n",
    "            labels = self.target_transform(labels)\n",
    "        return values, labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:10.472080211Z",
     "start_time": "2023-08-06T17:51:10.429214836Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class PyplineOfSunModule:\n",
    "    def __init__(self, model: SumNaturalBinAutoEncoder):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, x: int, y: int):\n",
    "        expected = x + y\n",
    "        x_arr = SimpleRandomNaturalBinSumDataset.decompose_to_bool_array(x)\n",
    "        y_arr = SimpleRandomNaturalBinSumDataset.decompose_to_bool_array(y)\n",
    "        model_input = torch.tensor(np.concatenate((x_arr, y_arr)))\n",
    "        predictions = self.model.predict(model_input).detach().numpy().round()\n",
    "        print(f\"Prediction:\\t{predictions}\")\n",
    "        print(f\"Expected:\\t{SimpleRandomNaturalBinSumDataset.decompose_to_bool_array(expected)}\")\n",
    "        return SimpleRandomNaturalBinSumDataset.compose_from_bool_array(predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:10.474815466Z",
     "start_time": "2023-08-06T17:51:10.472527752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'autoencoder-V03.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m pypline_of_sum \u001B[38;5;241m=\u001B[39m PyplineOfSunModule(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mautoencoder-V03.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      2\u001B[0m pypline_of_sum\u001B[38;5;241m.\u001B[39mpredict(np\u001B[38;5;241m.\u001B[39mint32(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3\u001B[39m), np\u001B[38;5;241m.\u001B[39mint32(\u001B[38;5;241m5\u001B[39m))\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/torch/serialization.py:791\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[1;32m    788\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    789\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 791\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    792\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m    793\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m    794\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m    795\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m    796\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/torch/serialization.py:271\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 271\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    272\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    273\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/torch/serialization.py:252\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 252\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'autoencoder-V03.pt'"
     ]
    }
   ],
   "source": [
    "# pypline_of_sum = PyplineOfSunModule(torch.load(f\"autoencoder-V03.pt\"))\n",
    "# pypline_of_sum.predict(np.int32(-3), np.int32(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:52:08.309927271Z",
     "start_time": "2023-08-06T17:52:08.200725696Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "activation_fun = nn.Sigmoid()\n",
    "# layer_sizes = [INT_BITS, 8, 8, 8, INT_BITS]\n",
    "layer_sizes = [INT_BITS * 2, 512, 128, INT_BITS]\n",
    "# layer_sizes = [INT_BITS * 2, 128, INT_BITS]\n",
    "# layer_sizes = [1, 32, 32, 32, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:10.479791503Z",
     "start_time": "2023-08-06T17:51:10.475106983Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:08<00:00, 123750.25it/s]\n",
      "100%|██████████| 1000000/1000000 [00:08<00:00, 124720.57it/s]\n",
      "100%|██████████| 1000000/1000000 [00:05<00:00, 178340.55it/s]\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 112857.11it/s]\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 113972.86it/s]\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 173219.57it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = SimpleRandomNaturalBinSumDataset(1_000_000)\n",
    "train_loader = DataLoader(dataset, batch_size=10_000,\n",
    "                          num_workers=multiprocessing.cpu_count(),\n",
    "                          )\n",
    "valid_dataset = SimpleRandomNaturalBinSumDataset(100_000)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=5_000,\n",
    "                          num_workers=multiprocessing.cpu_count(),\n",
    "                          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:37.414332899Z",
     "start_time": "2023-08-06T17:51:10.476151177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# model\n",
    "autoencoder = SumNaturalBinAutoEncoder(SumBinModule(32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:54:03.071646056Z",
     "start_time": "2023-08-06T17:54:03.057895241Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:03<00:00, 125992.10it/s]\n",
      "100%|██████████| 500000/500000 [00:03<00:00, 125790.38it/s]\n",
      "100%|██████████| 500000/500000 [00:02<00:00, 181203.22it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SimpleRandomNaturalBinSumDataset(500_000)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, num_workers=multiprocessing.cpu_count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-06T17:51:37.455982029Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cebad4fd463496d88547fd644c8d99d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[500, 2]' is invalid for input of size 64000",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m trainer \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mTrainer(max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# trainer.fit(autoencoder, train_dataloaders=train_loader)\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautoencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:735\u001B[0m, in \u001B[0;36mTrainer.test\u001B[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001B[0m\n\u001B[1;32m    733\u001B[0m     model \u001B[38;5;241m=\u001B[39m _maybe_unwrap_optimized(model)\n\u001B[1;32m    734\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m--> 735\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    736\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_test_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\n\u001B[1;32m    737\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:42\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     41\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     45\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:778\u001B[0m, in \u001B[0;36mTrainer._test_impl\u001B[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001B[0m\n\u001B[1;32m    773\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mattach_data(model, test_dataloaders\u001B[38;5;241m=\u001B[39mdataloaders, datamodule\u001B[38;5;241m=\u001B[39mdatamodule)\n\u001B[1;32m    775\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    776\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn, ckpt_path, model_provided\u001B[38;5;241m=\u001B[39mmodel_provided, model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    777\u001B[0m )\n\u001B[0;32m--> 778\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    779\u001B[0m \u001B[38;5;66;03m# remove the tensors from the test results\u001B[39;00m\n\u001B[1;32m    780\u001B[0m results \u001B[38;5;241m=\u001B[39m convert_tensors_to_scalars(results)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:973\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    968\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    970\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    971\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    972\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 973\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    976\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    977\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    978\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1009\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1006\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun-stage\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1008\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluating:\n\u001B[0;32m-> 1009\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_evaluation_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1010\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[1;32m   1011\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_loop\u001B[38;5;241m.\u001B[39mrun()\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:177\u001B[0m, in \u001B[0;36m_no_grad_context.<locals>._decorator\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    175\u001B[0m     context_manager \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mno_grad\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context_manager():\n\u001B[0;32m--> 177\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloop_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:115\u001B[0m, in \u001B[0;36m_EvaluationLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    113\u001B[0m     previous_dataloader_idx \u001B[38;5;241m=\u001B[39m dataloader_idx\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;66;03m# run step hooks\u001B[39;00m\n\u001B[0;32m--> 115\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_evaluation_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_idx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001B[39;00m\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:375\u001B[0m, in \u001B[0;36m_EvaluationLoop._evaluation_step\u001B[0;34m(self, batch, batch_idx, dataloader_idx)\u001B[0m\n\u001B[1;32m    372\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_started()\n\u001B[1;32m    374\u001B[0m hook_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_step\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mtesting \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation_step\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 375\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstep_kwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_processed()\n\u001B[1;32m    379\u001B[0m hook_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_test_batch_end\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mtesting \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_validation_batch_end\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:291\u001B[0m, in \u001B[0;36m_call_strategy_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    288\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 291\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m    294\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:388\u001B[0m, in \u001B[0;36mStrategy.test_step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mtest_step_context():\n\u001B[1;32m    387\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, TestStep)\n\u001B[0;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[12], line 24\u001B[0m, in \u001B[0;36mSumNaturalBinAutoEncoder.test_step\u001B[0;34m(self, batch, batch_idx)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtest_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, batch_idx):\n\u001B[1;32m     23\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m---> 24\u001B[0m     y_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_function(y_hat, y)\n\u001B[1;32m     26\u001B[0m     acc, bin_acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_accuracy(y_hat, y)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/ML-H-spring_semesester_project-nJO6SWcT/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[23], line 10\u001B[0m, in \u001B[0;36mSumBinModule.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x:  torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 10\u001B[0m     reshaped \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     after_and \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mAND(reshaped)\n\u001B[1;32m     12\u001B[0m     after_xor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mXOR(reshaped)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: shape '[500, 2]' is invalid for input of size 64000"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "trainer = pl.Trainer(max_epochs=30)\n",
    "\n",
    "# trainer.fit(autoencoder, train_dataloaders=train_loader)\n",
    "trainer.test(autoencoder, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:54:08.113858482Z",
     "start_time": "2023-08-06T17:54:05.923335764Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "autoencoder.lr = 0.0025\n",
    "# for i in range(5):\n",
    "# print(\"#\" * 40 + \" \" * 10 + f\"Iteration № {i:5}\" + \" \" * 10 + \"#\" * 40)\n",
    "trainer = pl.Trainer(max_epochs=50)\n",
    "trainer.fit(autoencoder, train_dataloaders=train_loader)\n",
    "trainer.test(autoencoder, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T17:51:53.995716210Z",
     "start_time": "2023-08-06T17:51:53.971080362Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(autoencoder, f\"./models/autoencoder-[128-64]-V05.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-06T17:51:53.971653268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# x_rand = torch.tensor(np.random.randint(low=0, high=2, size=(1, INT_BITS)).astype(np.float64))\n",
    "# y_hat = autoencoder.predict(x_rand).round()\n",
    "# print(x_rand == y_hat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-06T17:51:53.972720578Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import plotly.express as px"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-06T17:51:53.973306334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(x[0].astype(int))\n",
    "# print(y[0])\n",
    "# print(y[0].round().astype(int))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-06T17:51:53.973875398Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(x_to_plot)\n",
    "# print(y_to_plot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-06T17:51:53.974280266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fig = px.line(x=x_to_plot, y=y_to_plot)\n",
    "# fig.show()\n",
    "# \n",
    "# fig = px.line(x=x_to_plot, y=differ.sum(axis=1))\n",
    "# fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-08-06T17:51:53.974745757Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
