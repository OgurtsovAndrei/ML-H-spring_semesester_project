# # -*- coding: utf-8 -*-
# """hardml_week6_part1.ipynb
#
# Automatically generated by Colaboratory.
#
# Original file is located at
#     https://colab.research.google.com/drive/1Eya4IrrzDIWcmLvksbshDsX3_NrixuS5
#
# # 1. Transfer learning, popular architectures, pretrained models
# Предобученные модели: https://pytorch.org/vision/0.13/models.html#object-detection-instance-segmentation-and-person-keypoint-detection
#
# Заморозка сетки: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor
# """
#
# import torch
# import torchvision
#
# from torchvision.models import resnet18, resnet50, efficientnet_v2_s, ResNet50_Weights
# from torch.nn import Linear
#
# classifier_1 = resnet18()
# classifier_1.fc = Linear(..., 2)
# classifier_2 = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)
# classifier_3 = efficientnet_v2_s()
#
# classifier_1
#
# sum(param.numel() for param in classifier_1.parameters()), sum(param.numel() for param in classifier_3.parameters())
#
# from torchvision.models.segmentation import deeplabv3_resnet50
#
# segmenter = deeplabv3_resnet50()
# segmenter
#
# from torchvision.models.detection import fcos_resnet50_fpn
#
# detector = fcos_resnet50_fpn()
# detector.eval()
# x = torch.randn(2, 3, 32, 32)
# outs = detector(x)
#
# outs
#
# """# 2. PyTorch Lightning, infrastructure
#
# https://pytorch-lightning.readthedocs.io/en/latest/model/train_model_basic.html
#
# https://huggingface.co/docs/transformers/main_classes/trainer
#
# https://drivendata.github.io/cookiecutter-data-science/
# """
#
# !pip install pytorch-lightning
#
# import pytorch_lightning as pl
# import torch
# import torch.nn as nn
# import torch.nn.functional as F
#
# """## 2.1. Model"""
#
# class Encoder(nn.Module):
#     def __init__(self):
#         super().__init__()
#         self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))
#
#     def forward(self, x):
#         return self.l1(x)
#
#
# class Decoder(nn.Module):
#     def __init__(self):
#         super().__init__()
#         self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))
#
#     def forward(self, x):
#         return self.l1(x)
#
#
# class LitAutoEncoder(pl.LightningModule):
#     def __init__(self, encoder, decoder):
#         super().__init__()
#         self.encoder = encoder
#         self.decoder = decoder
#
#     def training_step(self, batch, batch_idx):
#         # training_step defines the train loop.
#         x, y = batch
#         x = x.view(x.size(0), -1)
#         z = self.encoder(x)
#         x_hat = self.decoder(z)
#         loss = F.mse_loss(x_hat, x)
#         return loss
#
#     def configure_optimizers(self):
#         optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)
#         return optimizer
#
# """## 2.2. Data"""
#
# import os
# import torchvision.transforms as transforms
# from torch.utils.data import DataLoader
# from torchvision.datasets import MNIST
#
# dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())
# train_loader = DataLoader(dataset)
#
# """## 2.3. Train loop"""
#
# # model
# autoencoder = LitAutoEncoder(Encoder(), Decoder())
#
# # train model
# trainer = pl.Trainer()
# trainer.fit(model=autoencoder, train_dataloaders=train_loader)
#
# sum(param.numel() for param in autoencoder.parameters())
#
# """# 3. Project: data, model and trainer from community"""
#
# !pip install lightning-bolts
#
# import os
# from pl_bolts.datamodules import CIFAR10DataModule
# from pl_bolts.transforms.dataset_normalizations import cifar10_normalization
#
#
# PATH_DATASETS = os.environ.get("PATH_DATASETS", ".")
# BATCH_SIZE = 256 if torch.cuda.is_available() else 64
# NUM_WORKERS = int(os.cpu_count() / 2)
# train_transforms = torchvision.transforms.Compose(
#     [
#         torchvision.transforms.RandomCrop(32, padding=4),
#         torchvision.transforms.RandomHorizontalFlip(),
#         torchvision.transforms.ToTensor(),
#         cifar10_normalization(),
#     ]
# )
#
# test_transforms = torchvision.transforms.Compose(
#     [
#         torchvision.transforms.ToTensor(),
#         cifar10_normalization(),
#     ]
# )
#
# cifar10_dm = CIFAR10DataModule(
#     data_dir=PATH_DATASETS,
#     batch_size=BATCH_SIZE,
#     num_workers=NUM_WORKERS,
#     train_transforms=train_transforms,
#     test_transforms=test_transforms,
#     val_transforms=test_transforms,
# )
#
# def create_model():
#     model = torchvision.models.resnet18(pretrained=False, num_classes=10)
#     model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
#     model.maxpool = nn.Identity()
#     return model
#
# class LitResnet(pl.LightningModule):
#     def __init__(self, lr=0.05):
#         super().__init__()
#
#         self.save_hyperparameters()
#         self.model = create_model()
#
#     def forward(self, x):
#         out = self.model(x)
#         return F.log_softmax(out, dim=1)
#
#     def training_step(self, batch, batch_idx):
#         x, y = batch
#         logits = self(x)
#         loss = F.nll_loss(logits, y)
#         self.log("train_loss", loss)
#         return loss
#
#     def evaluate(self, batch, stage=None):
#         x, y = batch
#         logits = self(x)
#         loss = F.nll_loss(logits, y)
#         preds = torch.argmax(logits, dim=1)
#
#         if stage:
#             self.log(f"{stage}_loss", loss, prog_bar=True)
#
#     def validation_step(self, batch, batch_idx):
#         self.evaluate(batch, "val")
#
#     def test_step(self, batch, batch_idx):
#         self.evaluate(batch, "test")
#
#     def configure_optimizers(self):
#         optimizer = torch.optim.SGD(
#             self.parameters(),
#             lr=self.hparams.lr,
#             momentum=0.9,
#             weight_decay=5e-4,
#         )
#         steps_per_epoch = 45000 // BATCH_SIZE
#
#         return optimizer
#
# model = LitResnet(lr=0.05)
#
# from pytorch_lightning.loggers import CSVLogger
#
# trainer = pl.Trainer(
#     max_epochs=30,
#     accelerator="auto",
#     devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs
#     logger=CSVLogger(save_dir="logs/"),
# )
#
# trainer.fit(model, cifar10_dm)
# trainer.test(model, datamodule=cifar10_dm)